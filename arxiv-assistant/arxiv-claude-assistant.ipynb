{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7V1M4ktoTLaF"
      },
      "outputs": [],
      "source": [
        "import arxiv\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75GMv_pcTNm5",
        "outputId": "9550b52a-96cc-4527-c3b9-1cac542b6099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: arxiv in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: python-dotenv in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: anthropic in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (0.47.1)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: requests~=2.32.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from arxiv) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: sgmllib3k in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: certifi in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yashbhalgat/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2.4.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install arxiv python-dotenv anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oJFOGWjrTT-J"
      },
      "outputs": [],
      "source": [
        "PAPER_DIR = \"papers\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQcUuF9ZTdkv"
      },
      "source": [
        "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the papers directory. The tool does not download the papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hreYrWnzTcp8"
      },
      "outputs": [],
      "source": [
        "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    Search for papers on arXiv based on a topic and store their information.\n",
        "\n",
        "    Args:\n",
        "        topic: The topic to search for\n",
        "        max_results: Maximum number of results to retrieve (default: 5)\n",
        "\n",
        "    Returns:\n",
        "        List of paper IDs found in the search\n",
        "    \"\"\"\n",
        "\n",
        "    # Use arxiv to find the papers\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Search for the most relevant articles matching the queried topic\n",
        "    search = arxiv.Search(\n",
        "        query = topic,\n",
        "        max_results = max_results,\n",
        "        sort_by = arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    papers = client.results(search)\n",
        "\n",
        "    # Create directory for this topic\n",
        "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(path, \"papers_info.json\")\n",
        "\n",
        "    # Try to load existing papers info\n",
        "    try:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            papers_info = json.load(json_file)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        papers_info = {}\n",
        "\n",
        "    # Process each paper and add to papers_info\n",
        "    paper_ids = []\n",
        "    for paper in papers:\n",
        "        paper_ids.append(paper.get_short_id())\n",
        "        paper_info = {\n",
        "            'title': paper.title,\n",
        "            'authors': [author.name for author in paper.authors],\n",
        "            'summary': paper.summary,\n",
        "            'pdf_url': paper.pdf_url,\n",
        "            'published': str(paper.published.date())\n",
        "        }\n",
        "        papers_info[paper.get_short_id()] = paper_info\n",
        "\n",
        "    # Save updated papers_info to json file\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump(papers_info, json_file, indent=2)\n",
        "\n",
        "    print(f\"Results are saved in: {file_path}\")\n",
        "\n",
        "    return paper_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRMZLoxZTqxx",
        "outputId": "f352520a-429e-477b-c354-afca25b28056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results are saved in: papers/computers/papers_info.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['1310.7911v2',\n",
              " 'math/9711204v1',\n",
              " '2208.00733v1',\n",
              " '2504.07020v1',\n",
              " '2403.03925v1']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_papers(\"computers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgxhhEyDUefm"
      },
      "source": [
        "The second tool looks for information about a specific paper across all topic directories inside the papers directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wGMvoOtvTtPT"
      },
      "outputs": [],
      "source": [
        "def extract_info(paper_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific paper across all topic directories.\n",
        "\n",
        "    Args:\n",
        "        paper_id: The ID of the paper to look for\n",
        "\n",
        "    Returns:\n",
        "        JSON string with paper information if found, error message if not found\n",
        "    \"\"\"\n",
        "\n",
        "    for item in os.listdir(PAPER_DIR):\n",
        "        item_path = os.path.join(PAPER_DIR, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as json_file:\n",
        "                        papers_info = json.load(json_file)\n",
        "                        if paper_id in papers_info:\n",
        "                            return json.dumps(papers_info[paper_id], indent=2)\n",
        "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    return f\"There's no saved information related to paper {paper_id}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "Is1DU3ANUl86",
        "outputId": "f90d5b5c-39ae-4052-9da2-288fecee6ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extract_info('1310.7911v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XWM3QwUVASD"
      },
      "source": [
        "# Tool Schema\n",
        "\n",
        "Here are the schema of each tool which you will provide to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G2p30jp4UrDY"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"name\": \"search_papers\",\n",
        "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"topic\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The topic to search for\"\n",
        "                },\n",
        "                \"max_results\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Maximum number of results to retrieve\",\n",
        "                    \"default\": 5\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"topic\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"extract_info\",\n",
        "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"paper_id\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The ID of the paper to look for\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"paper_id\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sbzZWn1VdzD"
      },
      "source": [
        "# Tool mapping\n",
        "\n",
        "This code handles tool mapping and execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aEDq3MuyU-9a"
      },
      "outputs": [],
      "source": [
        "mapping_tool_function = {\n",
        "    \"search_papers\": search_papers,\n",
        "    \"extract_info\": extract_info\n",
        "}\n",
        "\n",
        "def execute_tool(tool_name, tool_args):\n",
        "\n",
        "    result = mapping_tool_function[tool_name](**tool_args)\n",
        "\n",
        "    if result is None:\n",
        "        result = \"The operation completed but didn't return any results.\"\n",
        "\n",
        "    elif isinstance(result, list):\n",
        "        result = ', '.join(result)\n",
        "\n",
        "    elif isinstance(result, dict):\n",
        "        # Convert dictionaries to formatted JSON strings\n",
        "        result = json.dumps(result, indent=2)\n",
        "\n",
        "    else:\n",
        "        # For any other type, convert using str()\n",
        "        result = str(result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-WJ3BqeVdCJ"
      },
      "outputs": [],
      "source": [
        "client = anthropic.Anthropic(api_key='YOUR_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_Il3OG4CYKFg"
      },
      "outputs": [],
      "source": [
        "def process_query(query):\n",
        "\n",
        "    messages = [{'role': 'user', 'content': query}]\n",
        "\n",
        "    response = client.messages.create(max_tokens = 2024,\n",
        "                                  model = 'claude-3-7-sonnet-20250219',\n",
        "                                  tools = tools,\n",
        "                                  messages = messages)\n",
        "\n",
        "    process_query = True\n",
        "    while process_query:\n",
        "        assistant_content = []\n",
        "\n",
        "        for content in response.content:\n",
        "            if content.type == 'text':\n",
        "\n",
        "                print(content.text)\n",
        "                assistant_content.append(content)\n",
        "\n",
        "                if len(response.content) == 1:\n",
        "                    process_query = False\n",
        "\n",
        "            elif content.type == 'tool_use':\n",
        "\n",
        "                assistant_content.append(content)\n",
        "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
        "\n",
        "                tool_id = content.id\n",
        "                tool_args = content.input\n",
        "                tool_name = content.name\n",
        "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
        "\n",
        "                result = execute_tool(tool_name, tool_args)\n",
        "                messages.append({\"role\": \"user\",\n",
        "                                  \"content\": [\n",
        "                                      {\n",
        "                                          \"type\": \"tool_result\",\n",
        "                                          \"tool_use_id\": tool_id,\n",
        "                                          \"content\": result\n",
        "                                      }\n",
        "                                  ]\n",
        "                                })\n",
        "                response = client.messages.create(max_tokens = 2024,\n",
        "                                  model = 'claude-3-7-sonnet-20250219',\n",
        "                                  tools = tools,\n",
        "                                  messages = messages)\n",
        "\n",
        "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
        "                    print(response.content[0].text)\n",
        "                    process_query = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "taM6A_UxZWuE"
      },
      "outputs": [],
      "source": [
        "def chat_loop():\n",
        "    print(\"Type your queries or 'quit' to exit.\")\n",
        "    while True:\n",
        "        try:\n",
        "            query = input(\"\\nQuery: \").strip()\n",
        "            if query.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            process_query(query)\n",
        "            print(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e76-fP8zZdK-",
        "outputId": "12fe1a06-9c0d-457b-e914-4c8131792eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type your queries or 'quit' to exit.\n",
            "\n",
            "Query: Search for papers on \"LLM interpretability\"\n",
            "I'll search for papers on LLM interpretability for you. Let me retrieve that information.\n",
            "Calling tool search_papers with args {'topic': 'LLM interpretability', 'max_results': 5}\n",
            "Results are saved in: papers/llm_interpretability/papers_info.json\n",
            "I've found 5 papers related to LLM interpretability. Here are the paper IDs:\n",
            "\n",
            "1. 2412.07992v3\n",
            "2. 2402.01761v1 \n",
            "3. 2407.04307v1\n",
            "4. 2408.13006v2\n",
            "5. 2308.08728v1\n",
            "\n",
            "Would you like me to extract more detailed information about any of these specific papers? If so, please let me know which paper ID you're interested in.\n",
            "\n",
            "\n",
            "\n",
            "Query: Give me a summary of this paper 2412.07992v3\n",
            "I'll help you find information about this paper. The ID you provided (2412.07992v3) appears to be an arXiv paper ID. Let me use the extract_info function to retrieve details about this specific paper.\n",
            "Calling tool extract_info with args {'paper_id': '2412.07992v3'}\n",
            "# Summary of \"Concept Bottleneck Large Language Models\"\n",
            "\n",
            "## Paper Information\n",
            "- **Title**: Concept Bottleneck Large Language Models (CB-LLMs)\n",
            "- **Authors**: Chung-En Sun, Tuomas Oikarinen, Berk Ustun, Tsui-Wei Weng\n",
            "- **Published**: December 11, 2024\n",
            "- **arXiv ID**: 2412.07992v3\n",
            "\n",
            "## Key Points\n",
            "\n",
            "This paper introduces Concept Bottleneck Large Language Models (CB-LLMs), a framework that builds interpretability directly into Large Language Models rather than relying on post-hoc interpretation methods. The key innovation is that CB-LLMs integrate intrinsic interpretability into the model architecture itself.\n",
            "\n",
            "The researchers developed CB-LLMs for two main NLP tasks:\n",
            "\n",
            "1. **Text Classification**: The CB-LLM approach achieves competitive and sometimes superior performance compared to traditional black-box models while providing explicit and interpretable reasoning for its decisions.\n",
            "\n",
            "2. **Text Generation**: The model incorporates interpretable neurons that enable:\n",
            "   - Precise concept detection\n",
            "   - Controlled text generation\n",
            "   - Safer outputs\n",
            "\n",
            "## Benefits and Applications\n",
            "\n",
            "The built-in interpretability of CB-LLMs offers several advantages:\n",
            "- Allows users to transparently identify harmful content\n",
            "- Enables steering of model behavior\n",
            "- Provides mechanisms to unlearn undesired concepts\n",
            "\n",
            "These capabilities significantly enhance the safety, reliability, and trustworthiness of LLMs - features that are notably lacking in existing models.\n",
            "\n",
            "The paper's code is publicly available at: https://github.com/Trustworthy-ML-Lab/CB-LLMs\n",
            "\n",
            "\n",
            "\n",
            "Query: quit\n"
          ]
        }
      ],
      "source": [
        "chat_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zGU-dtP3ZhkV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mcp_project/research_server.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mcp_project/research_server.py\n",
        "\n",
        "import arxiv\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "\n",
        "PAPER_DIR = \"papers\"\n",
        "\n",
        "# Initialize FastMCP server\n",
        "mcp = FastMCP(\"research\")\n",
        "\n",
        "@mcp.tool()\n",
        "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    Search for papers on arXiv based on a topic and store their information.\n",
        "    \n",
        "    Args:\n",
        "        topic: The topic to search for\n",
        "        max_results: Maximum number of results to retrieve (default: 5)\n",
        "        \n",
        "    Returns:\n",
        "        List of paper IDs found in the search\n",
        "    \"\"\"\n",
        "    \n",
        "    # Use arxiv to find the papers \n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Search for the most relevant articles matching the queried topic\n",
        "    search = arxiv.Search(\n",
        "        query = topic,\n",
        "        max_results = max_results,\n",
        "        sort_by = arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    papers = client.results(search)\n",
        "    \n",
        "    # Create directory for this topic\n",
        "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    \n",
        "    file_path = os.path.join(path, \"papers_info.json\")\n",
        "\n",
        "    # Try to load existing papers info\n",
        "    try:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            papers_info = json.load(json_file)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        papers_info = {}\n",
        "\n",
        "    # Process each paper and add to papers_info  \n",
        "    paper_ids = []\n",
        "    for paper in papers:\n",
        "        paper_ids.append(paper.get_short_id())\n",
        "        paper_info = {\n",
        "            'title': paper.title,\n",
        "            'authors': [author.name for author in paper.authors],\n",
        "            'summary': paper.summary,\n",
        "            'pdf_url': paper.pdf_url,\n",
        "            'published': str(paper.published.date())\n",
        "        }\n",
        "        papers_info[paper.get_short_id()] = paper_info\n",
        "    \n",
        "    # Save updated papers_info to json file\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump(papers_info, json_file, indent=2)\n",
        "    \n",
        "    print(f\"Results are saved in: {file_path}\")\n",
        "    \n",
        "    return paper_ids\n",
        "\n",
        "@mcp.tool()\n",
        "def extract_info(paper_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific paper across all topic directories.\n",
        "    \n",
        "    Args:\n",
        "        paper_id: The ID of the paper to look for\n",
        "        \n",
        "    Returns:\n",
        "        JSON string with paper information if found, error message if not found\n",
        "    \"\"\"\n",
        " \n",
        "    for item in os.listdir(PAPER_DIR):\n",
        "        item_path = os.path.join(PAPER_DIR, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as json_file:\n",
        "                        papers_info = json.load(json_file)\n",
        "                        if paper_id in papers_info:\n",
        "                            return json.dumps(papers_info[paper_id], indent=2)\n",
        "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
        "                    continue\n",
        "    \n",
        "    return f\"There's no saved information related to paper {paper_id}.\"\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize and run the server\n",
        "    mcp.run(transport='stdio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['DLAI_LOCAL_URL'] = \"http://localhost:{port}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"768\"\n",
              "            src=\"http://localhost:8888/terminals/1\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x119222ef0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# start a new terminal\n",
        "import os\n",
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/1\", \n",
        "       width=600, height=768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inspector Proxy Address that you need to specify under configuration in the inspector UI:\n",
            "http://localhost:6277\n"
          ]
        }
      ],
      "source": [
        "# Print the inspector proxy address\n",
        "print(\"Inspector Proxy Address that you need to specify under configuration in the inspector UI:\")\n",
        "print(os.environ.get('DLAI_LOCAL_URL').format(port=6277)[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reference Code\n",
        "``` python\n",
        "from mcp import ClientSession, StdioServerParameters, types\n",
        "from mcp.client.stdio import stdio_client\n",
        "\n",
        "# Create server parameters for stdio connection\n",
        "server_params = StdioServerParameters(\n",
        "    command=\"uv\",  # Executable\n",
        "    args=[\"run example_server.py\"],  # Command line arguments\n",
        "    env=None,  # Optional environment variables\n",
        ")\n",
        "\n",
        "async def run():\n",
        "    # Launch the server as a subprocess & returns the read and write streams\n",
        "    # read: the stream that the client will use to read msgs from the server\n",
        "    # write: the stream that client will use to write msgs to the server\n",
        "    async with stdio_client(server_params) as (read, write): \n",
        "        # the client session is used to initiate the connection \n",
        "        # and send requests to server \n",
        "        async with ClientSession(read, write) as session:\n",
        "            # Initialize the connection (1:1 connection with the server)\n",
        "            await session.initialize()\n",
        "\n",
        "            # List available tools\n",
        "            tools = await session.list_tools()\n",
        "\n",
        "            # will call the chat_loop here\n",
        "            # ....\n",
        "            \n",
        "            # Call a tool: this will be in the process_query method\n",
        "            result = await session.call_tool(\"tool-name\", arguments={\"arg1\": \"value\"})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(run())\n",
        "`````"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mcp_project/mcp_chatbot.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mcp_project/mcp_chatbot.py\n",
        "from dotenv import load_dotenv\n",
        "from anthropic import Anthropic\n",
        "from mcp import ClientSession, StdioServerParameters, types\n",
        "from mcp.client.stdio import stdio_client\n",
        "from typing import List\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "class MCP_ChatBot:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize session and client objects\n",
        "        self.session: ClientSession = None\n",
        "        self.anthropic = Anthropic()\n",
        "        self.available_tools: List[dict] = []\n",
        "\n",
        "    async def process_query(self, query):\n",
        "        messages = [{'role':'user', 'content':query}]\n",
        "        response = self.anthropic.messages.create(max_tokens = 2024,\n",
        "                                      model = 'claude-3-7-sonnet-20250219', \n",
        "                                      tools = self.available_tools, # tools exposed to the LLM\n",
        "                                      messages = messages)\n",
        "        process_query = True\n",
        "        while process_query:\n",
        "            assistant_content = []\n",
        "            for content in response.content:\n",
        "                if content.type =='text':\n",
        "                    print(content.text)\n",
        "                    assistant_content.append(content)\n",
        "                    if(len(response.content) == 1):\n",
        "                        process_query= False\n",
        "                elif content.type == 'tool_use':\n",
        "                    assistant_content.append(content)\n",
        "                    messages.append({'role':'assistant', 'content':assistant_content})\n",
        "                    tool_id = content.id\n",
        "                    tool_args = content.input\n",
        "                    tool_name = content.name\n",
        "    \n",
        "                    print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
        "                    \n",
        "                    # Call a tool\n",
        "                    #result = execute_tool(tool_name, tool_args): not anymore needed\n",
        "                    # tool invocation through the client session\n",
        "                    result = await self.session.call_tool(tool_name, arguments=tool_args)\n",
        "                    messages.append({\"role\": \"user\", \n",
        "                                      \"content\": [\n",
        "                                          {\n",
        "                                              \"type\": \"tool_result\",\n",
        "                                              \"tool_use_id\":tool_id,\n",
        "                                              \"content\": result.content\n",
        "                                          }\n",
        "                                      ]\n",
        "                                    })\n",
        "                    response = self.anthropic.messages.create(max_tokens = 2024,\n",
        "                                      model = 'claude-3-7-sonnet-20250219', \n",
        "                                      tools = self.available_tools,\n",
        "                                      messages = messages) \n",
        "                    \n",
        "                    if(len(response.content) == 1 and response.content[0].type == \"text\"):\n",
        "                        print(response.content[0].text)\n",
        "                        process_query= False\n",
        "\n",
        "    \n",
        "    \n",
        "    async def chat_loop(self):\n",
        "        \"\"\"Run an interactive chat loop\"\"\"\n",
        "        print(\"\\nMCP Chatbot Started!\")\n",
        "        print(\"Type your queries or 'quit' to exit.\")\n",
        "        \n",
        "        while True:\n",
        "            try:\n",
        "                query = input(\"\\nQuery: \").strip()\n",
        "        \n",
        "                if query.lower() == 'quit':\n",
        "                    break\n",
        "                    \n",
        "                await self.process_query(query)\n",
        "                print(\"\\n\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"\\nError: {str(e)}\")\n",
        "    \n",
        "    async def connect_to_server_and_run(self):\n",
        "        # Create server parameters for stdio connection\n",
        "        server_params = StdioServerParameters(\n",
        "            command=\"uv\",  # Executable\n",
        "            args=[\"run\", \"research_server.py\"],  # Optional command line arguments\n",
        "            env=None,  # Optional environment variables\n",
        "        )\n",
        "        async with stdio_client(server_params) as (read, write):\n",
        "            async with ClientSession(read, write) as session:\n",
        "                self.session = session\n",
        "                # Initialize the connection\n",
        "                await session.initialize()\n",
        "    \n",
        "                # List available tools\n",
        "                response = await session.list_tools()\n",
        "                \n",
        "                tools = response.tools\n",
        "                print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])\n",
        "                \n",
        "                self.available_tools = [{\n",
        "                    \"name\": tool.name,\n",
        "                    \"description\": tool.description,\n",
        "                    \"input_schema\": tool.inputSchema\n",
        "                } for tool in response.tools]\n",
        "    \n",
        "                await self.chat_loop()\n",
        "\n",
        "\n",
        "async def main():\n",
        "    chatbot = MCP_ChatBot()\n",
        "    await chatbot.connect_to_server_and_run()\n",
        "  \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
